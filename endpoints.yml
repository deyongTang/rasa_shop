# This file contains the different endpoints your bot can use.

# Server where the models are pulled from.
# https://rasa.com/docs/rasa-pro/production/model-storage#fetching-models-from-a-server

#models:
#  url: http://my-server.com/models/default_core@latest
#  wait_time_between_pulls:  10   # [optional](default: 100)

# Server which runs your custom actions.
# https://rasa.com/docs/rasa-pro/concepts/custom-actions

action_endpoint:
  actions_module: "actions"

# Tracker store which is used to store the conversations.
# By default the conversations are stored in memory.
# https://rasa.com/docs/rasa-pro/production/tracker-stores

#tracker_store:
#    type: redis
#    url: <host of the redis instance, e.g. localhost>
#    port: <port of your redis instance, usually 6379>
#    db: <number of your database within redis, e.g. 0>
#    password: <password used for authentication>
#    use_ssl: <whether or not the communication is encrypted, default false>

#tracker_store:
#    type: mongod
#    url: <url to your mongo instance, e.g. mongodb://localhost:27017>
#    db: <name of the db within your mongo instance, e.g. rasa>
#    username: <username used for authentication>
#    password: <password used for authentication>

# Event broker which all conversation events should be streamed to.
# https://rasa.com/docs/rasa-pro/production/event-brokers

#event_broker:
#  url: localhost
#  username: username
#  password: password
#  queue: queue

# The lines below activate contextual rephrasing, using the default OpenAI language model.
# Ensure the OPENAI_API_KEY is set to prevent any missing API key errors.
# For more details, refer to the documentation:
# https://rasa.com/docs/rasa-pro/concepts/contextual-response-rephraser
# To enable the rephraser, remove the comment symbols in the lines below.
#nlg:
#   type: rephrase
nlg:
  type: rephrase
  llm:
    model_group: qwen
#    model_group: qwen3_8b


model_groups:
#  - id: openai-gpt-4o
#    models:
#      - provider: openai
#        model: gpt-4o-2024-11-20
#        request_timeout: 7
#        max_tokens: 256

  - id: qwen
    models:
      - provider: self-hosted
#        model: qwen-turbo
        model: qwen-plus-2025-07-28
        api_base: "https://dashscope.aliyuncs.com/compatible-mode/v1"
        api_key: ${API_KEY}

  - id: qwen3_8b
    models:
      - provider: self-hosted
        model: Qwen3-8B-sft #与VLLM启动时指定的served-model-name保持一致，否则报错找不到模型
        api_base: "https://6b19befc5589.ngrok-free.app/v1"

  - id: embedding_models
    models:
      - model: bge-base-zh-v1.5
        api_base: "http://localhost:10010"
        api_key: ${API_KEY}

vector_store:
  neo4j_url: "neo4j://127.0.0.1"
  neo4j_auth:
    - neo4j
    - 'deyong123456'
